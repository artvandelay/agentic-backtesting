# Reflection Pattern Implementation Guide

## üéØ Overview

This implementation brings **Chapter 4: Reflection Pattern** from the Agentic Design Patterns textbook into NLBT, with an autonomous multi-phase workflow where the LLM controls phase transitions.

## üìñ Textbook Patterns Applied

### 1. **Reflection Pattern (Chapter 4)**
**Core Concept:** "An agent evaluates its own work, output, or internal state and uses that evaluation to improve its performance."

**Our Implementation:**
- **Producer-Critic Model**: Separate prompts for generation vs. evaluation
- **Iterative Refinement**: Each phase has internal reflection loops
- **Meta-Cognition**: LLM decides when it has sufficient info/quality to proceed

### 2. **Planning Pattern (Chapter 6)**  
**Core Concept:** "Evaluating a proposed plan and identifying potential flaws or improvements before execution."

**Our Implementation:**
- Phase 1 (Understanding) is explicit planning: gather requirements first
- Phase 3 (Reporting) plans report structure before writing
- No code generation until LLM confirms requirements are complete

### 3. **Goal Setting & Monitoring (Chapter 11)**
**Core Concept:** "A goal provides the ultimate benchmark for self-evaluation while monitoring tracks progress."

**Our Implementation:**
- Each phase has explicit success criteria
- LLM self-monitors against those criteria
- Phase transitions only when LLM confirms goal achievement

---

## üèóÔ∏è Architecture

### Three-Phase Workflow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   PHASE 1: UNDERSTANDING                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ User Message ‚Üí LLM Analyzes ‚Üí Extract Requirements   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚Üì                            ‚Üì                ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   Complete?  ‚Üê‚îÄ‚îÄNO‚îÄ‚îÄ‚îÄ  Ask Clarifying Question       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚Üì                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ       YES                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚Üì                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Transition to Phase 2                               ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  PHASE 2: IMPLEMENTATION                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Producer: Generate Code                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚Üì                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Execute in Sandbox                                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚Üì                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Critic: Evaluate Results                            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚Üì                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Meets Requirements? ‚Üê‚îÄ‚îÄNO‚îÄ‚îÄ Refine & Retry          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚Üì                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ       YES                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚Üì                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Transition to Phase 3                               ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PHASE 3: REPORTING                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Plan Report Structure                               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚Üì                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Write Report Draft                                   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚Üì                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Refine Report (Critic Reviews)                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚Üì                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Save Final Report                                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚Üì                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  COMPLETE                                             ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîç Phase Details

### Phase 1: Understanding (Requirements Gathering)

**Textbook Principle:** "By learning from past critiques, agents avoid repeating errors" (Chapter 4, pg 1125)

**Implementation:**
```python
def _phase_understanding(self, user_message: str) -> Dict[str, Any]:
    # LLM analyzes conversation and decides if it has enough info
    analysis_prompt = """
    Analyze what you have and what's missing.
    
    STATUS: [READY or INCOMPLETE]
    EXTRACTED_INFO: [ticker, period, capital, strategy]
    NEXT_ACTION: [ask for missing OR confirm ready]
    """
    
    if "STATUS: READY" in analysis:
        # LLM decides to transition
        self.current_phase = Phase.IMPLEMENTATION
    else:
        # LLM asks clarifying questions
        return ask_user_for_missing_info()
```

**Key Features:**
- ‚úÖ LLM has full autonomy to decide when sufficient
- ‚úÖ Structured output format ensures consistent parsing
- ‚úÖ No hardcoded validation rules - LLM uses reasoning
- ‚úÖ Maintains conversation history for context

---

### Phase 2: Implementation (Producer-Critic Loop)

**Textbook Principle:** "The Producer Agent focuses on generation; the Critic Agent evaluates with a fresh perspective" (Chapter 4, pg 1118-1121)

**Implementation:**
```python
def _phase_implementation(self, max_attempts: int = 3) -> Dict[str, Any]:
    for attempt in range(1, max_attempts + 1):
        # PRODUCER: Generate code
        code = self._generate_initial_code()  # or _refine_code()
        
        # EXECUTE: Run in sandbox
        result = self.executor.execute(code)
        
        # CRITIC: Evaluate
        critique = self._critique_implementation(code, result)
        
        # LLM DECISION: Proceed or retry?
        if "DECISION: PROCEED" in critique:
            self.current_phase = Phase.REPORTING
            return success
        elif "DECISION: RETRY" in critique:
            continue  # Critic says try again
```

**Producer Prompt:**
```
You are a Python backtesting expert. Write COMPLETE, EXECUTABLE code.
Requirements: [extracted from Phase 1]
Write ONLY the Python code, no explanations.
```

**Critic Prompt:**
```
You are a SENIOR BACKTESTING ENGINEER reviewing code.
Check: ticker, period, strategy, results quality
ASSESSMENT: [PASS or FAIL]
DECISION: [PROCEED if PASS, RETRY if FAIL]
FIXES_NEEDED: [specific changes if RETRY]
```

**Key Features:**
- ‚úÖ Separate personas prevent cognitive bias
- ‚úÖ Critic has different role & instructions than Producer
- ‚úÖ Multi-iteration with memory of previous attempts
- ‚úÖ Specific, actionable feedback for refinement

---

### Phase 3: Reporting (Plan ‚Üí Write ‚Üí Refine)

**Textbook Principle:** "Reflection adds meta-cognition, enabling learning from outputs" (Chapter 4, pg 1158)

**Implementation:**
```python
def _phase_reporting(self) -> Dict[str, Any]:
    # Step 1: PLAN
    plan = self._plan_report()  # LLM creates outline
    
    # Step 2: WRITE
    draft = self._write_report(plan)  # LLM writes from plan
    
    # Step 3: REFINE
    final = self._refine_report(draft)  # Critic reviews & improves
    
    # Save and complete
    save_report(final)
    self.current_phase = Phase.COMPLETE
```

**Planning Prompt:**
```
Based on backtest results, plan a comprehensive report.
Create a REPORT OUTLINE:
1. Executive Summary
2. Strategy Description  
3. Results & Metrics
4. Key Insights
5. Code Appendix
```

**Refinement Prompt:**
```
You are a FINANCIAL ANALYST reviewing a backtest report.
Evaluate: clarity, metrics, documentation, insights
Provide the REFINED VERSION (not just critique).
```

**Key Features:**
- ‚úÖ Explicit planning before execution (Chapter 6 pattern)
- ‚úÖ Structured workflow: plan ‚Üí draft ‚Üí refine
- ‚úÖ Final reflection loop ensures quality
- ‚úÖ Auto-saves report when complete

---

## üéÆ Usage

### New Command: `nlbt reflect`

```bash
# Start reflection mode
nlbt reflect

# With specific model
nlbt reflect --model claude-3-5-sonnet-20241022

# Example session:
üí≠ You: Test a moving average strategy on Apple

üîç [UNDERSTANDING] Processing...

ü§ñ Agent:
STATUS: INCOMPLETE
EXTRACTED_INFO:
- Ticker: AAPL ‚úì
- Period: MISSING
- Capital: MISSING  
- Strategy: Moving average (needs details: periods? crossover?)

NEXT_ACTION: What time period should I test (e.g., 2024, last year)?
And what's your initial capital?

üí≠ You: 2024 with $10,000, use 50/200 day MA crossover

ü§ñ Agent:
STATUS: READY
All requirements gathered!

üîÑ Moving to IMPLEMENTATION phase...

‚öôÔ∏è [IMPLEMENTATION] Processing...
[Generates code, executes, critiques, succeeds]

üîÑ Moving to REPORTING phase...

üìä [REPORTING] Processing...
[Plans report, writes, refines, saves]

‚úÖ Report complete! Saved to: reports/...
```

---

## üîë Key Design Decisions

### 1. **LLM Autonomy Over Hardcoded Rules**

**Traditional Approach:**
```python
if ticker and period and capital and strategy:
    proceed_to_implementation()
```

**Our Reflection Approach:**
```python
# Let LLM decide with reasoning
if llm.analyze("Do I have sufficient info?") == "READY":
    proceed_to_implementation()
```

**Why:** LLM can understand nuance (e.g., "last year" is sufficient even without exact dates).

---

### 2. **Structured Output Format**

Every LLM decision uses a rigid format:
```
STATUS: [READY/INCOMPLETE/PASS/FAIL]
REASONING: [explanation]
DECISION: [PROCEED/RETRY]
```

**Why:** Makes parsing reliable while preserving LLM reasoning transparency.

---

### 3. **Producer-Critic Separation**

```python
# Different system prompts
producer_prompt = "You are a Python expert. Generate code."
critic_prompt = "You are a senior engineer. Find flaws."
```

**Why:** From textbook pg 1118 - "prevents cognitive bias of self-review."

---

### 4. **Auto-Continuation Between Phases**

```python
if result.get('should_auto_continue'):
    if phase == IMPLEMENTATION:
        return self.engine.process_user_message("")  # Auto-trigger
```

**Why:** User describes strategy once; system autonomously executes all 3 phases.

---

## üìä Comparison: Old vs. New

| Aspect | Old (`core.py`) | New (`reflection_engine.py`) |
|--------|-----------------|------------------------------|
| **Requirements** | Hardcoded checks | LLM decides sufficiency |
| **Code Gen** | Single attempt | Producer-Critic loop (3x) |
| **Error Handling** | Dump error to chat | Structured critique & refinement |
| **Reporting** | Basic markdown | Plan ‚Üí Write ‚Üí Refine |
| **Phase Transitions** | Implicit | Explicit LLM-controlled |
| **Textbook Alignment** | Tool Use only | Reflection + Planning + Goal Monitoring |

---

## üß™ Testing the Reflection Pattern

### Test Case 1: Insufficient Info
```
You: "Test Apple stock"

Expected: LLM asks for period, capital, strategy
‚úÖ Phase stays in UNDERSTANDING
```

### Test Case 2: Complete Info
```
You: "Backtest AAPL with 50/200 MA crossover, 2024, $10K"

Expected: LLM extracts all requirements, moves to IMPLEMENTATION
‚úÖ Phase transitions automatically
```

### Test Case 3: Code Failure
```
Producer generates code with syntax error

Expected: Critic identifies error, Producer fixes it
‚úÖ Reflection loop iterates
```

### Test Case 4: Implementation Success
```
Code executes successfully

Expected: Critic validates it meets requirements, transitions to REPORTING
‚úÖ Phase advances autonomously
```

---

## üéì Textbook Alignment Summary

| Pattern | Chapter | How We Implement It |
|---------|---------|---------------------|
| **Reflection** | 4 | Producer-Critic loops in Phases 2 & 3 |
| **Prompt Chaining** | 1 | Sequential phases with context passing |
| **Planning** | 6 | Phase 1 gathers requirements before coding; Phase 3 plans report structure |
| **Tool Use** | 5 | Sandbox executor, data fetching |
| **Goal Setting** | 11 | Each phase has explicit success criteria |
| **Memory** | 8 | Conversation history maintained across phases |

---

## üöÄ Next Steps

### Immediate Enhancements
1. **Add Memory Management** (Chapter 8)
   - Compress old conversation turns
   - Maintain state dict across sessions

2. **Improve Critique Quality**
   - Add specific rubrics for evaluation
   - Use examples of good vs. bad code

3. **Guardrails** (Chapter 18)
   - Pre-execution code validation
   - Runtime limits

### Future Extensions
1. **Routing** (Chapter 2) - Different workflows for different strategy types
2. **Parallelization** (Chapter 3) - Compare multiple strategies simultaneously
3. **RAG** (Chapter 14) - Ground strategies in historical examples

---

## üí° Key Insights

1. **"The separation of Producer and Critic is powerful because it prevents cognitive bias"** (pg 1118)
   - We use distinct prompts for generation vs. evaluation
   - Critic approaches with "fresh perspective"

2. **"Reflection enables learning from past critiques"** (pg 1125)  
   - Each retry includes history of previous failures
   - LLM sees what didn't work before

3. **"Planning involves evaluating before execution"** (pg 1149)
   - Phase 1 completes before Phase 2 starts
   - No code generation without complete requirements

4. **"Memory provides context for evaluation"** (pg 1125)
   - Conversation history informs every LLM decision
   - State accumulates across phases

---

## üìù Configuration

Environment variables (`.env`):
```bash
LLM_MODEL=claude-3-5-sonnet-20241022  # Recommended for reasoning
CACHE_DIR=.cache
DEFAULT_TIMEOUT=120  # Longer for reflection loops
```

---

## üéØ Summary

This implementation transforms NLBT from a **single-prompt tool** into a **multi-phase agentic system** with:

‚úÖ **Autonomous decision-making** - LLM controls phase transitions  
‚úÖ **Self-evaluation** - Producer-Critic pattern prevents errors  
‚úÖ **Iterative refinement** - Reflection loops ensure quality  
‚úÖ **Explicit planning** - Requirements before implementation  
‚úÖ **Professional output** - Structured report generation  

All grounded in proven design patterns from the Agentic Design Patterns textbook.

